{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.imputation import mice\n",
    "from sklearn.utils import shuffle\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 (전처리 완료)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')\n",
    "train = pd.read_csv('data_p.csv')\n",
    "test = pd.read_csv('test_p.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최종 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 176, number of negative: 5279\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 11\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.032264 -> initscore=-3.401008\n",
      "[LightGBM] [Info] Start training from score -3.401008\n",
      "Training Time: 0.1449437141418457 seconds\n",
      "Prediction Time: 0.0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train should be your feature matrix (excluding the target variable), and y_train your target variable\n",
    "X_train = train.drop('Target', axis=1)\n",
    "y_train = train['Target']\n",
    "\n",
    "# X_test should be your feature matrix for the test set\n",
    "X_test = test\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "# Define LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'goss',\n",
    "    'num_leaves': 28, # You can experiment with this value\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.33,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'min_data_in_leaf': 40,\n",
    "    'scale_pos_weight': 33  # Adjust based on your positive rate (1 / positive_rate - 1)\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "num_round = 300\n",
    "bst = lgb.train(params, train_data, num_round)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training Time: {training_time} seconds\")\n",
    "\n",
    "# Measure prediction time\n",
    "start_time = time.time()\n",
    "\n",
    "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "prediction_time = time.time() - start_time\n",
    "print(f\"Prediction Time: {prediction_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a binary classification problem, you can convert probabilities to binary predictions\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "sample['Target'] = y_pred\n",
    "sample.to_csv(\"final_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
